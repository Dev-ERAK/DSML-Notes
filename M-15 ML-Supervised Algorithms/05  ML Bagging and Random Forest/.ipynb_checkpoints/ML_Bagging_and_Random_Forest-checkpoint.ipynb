{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQtcB6H61aIW"
   },
   "source": [
    "# Content\n",
    "\n",
    "- What are Ensemble Models?\n",
    "- Types of Ensembles\n",
    "- What is Bagging?\n",
    "  * [Ensemble Bagging Characteristics](https://www.scaler.com/hire/test/problem/16803/)\n",
    "  * [Why Bagging?](https://www.scaler.com/hire/test/problem/25818/)\n",
    "  * [Bagging is helpful for?](https://www.scaler.com/hire/test/problem/25850/)\n",
    "- Ensembling DTs - Random Forest\n",
    "- How to introduce randomness?\n",
    "- How to combine multiple DTs?\n",
    "  * [Different base learners](https://www.scaler.com/hire/test/problem/34588/)\n",
    "  * [Strong Predictor](https://www.scaler.com/hire/test/problem/25817/)\n",
    "  * [Random forest sampling](https://www.scaler.com/hire/test/problem/18824/)\n",
    "  * [Not Picking an Observation](https://www.scaler.com/hire/test/problem/25824/) - H/W\n",
    "- How to validate RFs?\n",
    "- OOB Score\n",
    "  * [Random Forest Validation Score](https://www.scaler.com/hire/test/problem/16806/)\n",
    "  * [OOB Score](https://www.scaler.com/hire/test/problem/25823/) - H/W\n",
    "- Bias Variance tradeoff\n",
    "- Training a RF model\n",
    "- RF Code Implementation\n",
    "- Hyperparameters of RF\n",
    "  * [Base Learners](https://www.scaler.com/hire/test/problem/25820/)\n",
    "  * [Hyperparameters in Forest](https://www.scaler.com/hire/test/problem/25830/)\n",
    "  * [Bagging](https://www.scaler.com/hire/test/problem/25809/) - (coding) H/W\n",
    "- Tuning the Hyperparameters (GridSearchCV)\n",
    "  * [Grid searching](https://www.scaler.com/hire/test/problem/25920/) - (coding) H/W\n",
    "- How to compute Feature Importances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oAVDhGtYwjpD"
   },
   "source": [
    "Miscellaneous\n",
    "\n",
    "* [Properties of base learners](https://www.scaler.com/hire/test/problem/34589/)\n",
    "* [Feature scaling in RandomForest](https://www.scaler.com/hire/test/problem/34590/)\n",
    "* [Advantages and disadvantages of Random Forest](https://www.scaler.com/hire/test/problem/18832/)\n",
    "* [String attributes\n",
    "](https://www.scaler.com/hire/test/problem/25813/) - (coding) H/W\n",
    "* [Boostrapping](https://www.scaler.com/hire/test/problem/25793/) - (coding) H/W\n",
    "* [Random Forest regressor](https://www.scaler.com/hire/test/problem/25822/) - (coding) H/W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Zcd8qWkyjFI"
   },
   "source": [
    "## Solving the Attrition problem for Jio!\n",
    "\n",
    "Recall in the previous lecture,\n",
    "\n",
    "**We were trying to predict whether an employee will stay or leave the company, to help the HR department of Jio improve their Attrition Rate.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0oiHR_JPf5p8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YK15a4m5aZmd",
    "outputId": "1d1b5ffc-134a-48cd-e677-6682c610fdf6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=16KtxSt_QEGQvfluEaMls5cCHPwhRXgCk\n",
      "To: E:\\Scaler-Notes-Git\\DSML-Notes\\M-15 ML-Supervised Algorithms\\05  ML Bagging and Random Forest\\HR-Employee-Attrition.csv\n",
      "\n",
      "  0%|          | 0.00/228k [00:00<?, ?B/s]\n",
      "100%|##########| 228k/228k [00:00<00:00, 2.09MB/s]\n",
      "100%|##########| 228k/228k [00:00<00:00, 2.07MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=19L3rYatfhbBL1r5MHrv-p_oM2wlvrhqk\n",
      "To: E:\\Scaler-Notes-Git\\DSML-Notes\\M-15 ML-Supervised Algorithms\\05  ML Bagging and Random Forest\\preprocessed_X_sm.pickle\n",
      "\n",
      "  0%|          | 0.00/534k [00:00<?, ?B/s]\n",
      " 98%|#########8| 524k/534k [00:00<00:00, 2.52MB/s]\n",
      "100%|##########| 534k/534k [00:00<00:00, 2.52MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OHLKJwA3qZopKPvlKoRldM6BvA1A4dYF\n",
      "To: E:\\Scaler-Notes-Git\\DSML-Notes\\M-15 ML-Supervised Algorithms\\05  ML Bagging and Random Forest\\X_test.pickle\n",
      "\n",
      "  0%|          | 0.00/111k [00:00<?, ?B/s]\n",
      "100%|##########| 111k/111k [00:00<00:00, 1.24MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1N7O_fWCTJLu8SIa_paKcDEzllgpMk8sK\n",
      "To: E:\\Scaler-Notes-Git\\DSML-Notes\\M-15 ML-Supervised Algorithms\\05  ML Bagging and Random Forest\\y_sm.pickle\n",
      "\n",
      "  0%|          | 0.00/15.4k [00:00<?, ?B/s]\n",
      "100%|##########| 15.4k/15.4k [00:00<00:00, 74.4kB/s]\n",
      "100%|##########| 15.4k/15.4k [00:00<00:00, 74.4kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=12Bh2AN8LcZAlg20ehpQrEWccUDaSdsOG\n",
      "To: E:\\Scaler-Notes-Git\\DSML-Notes\\M-15 ML-Supervised Algorithms\\05  ML Bagging and Random Forest\\y_test.pickle\n",
      "\n",
      "  0%|          | 0.00/9.49k [00:00<?, ?B/s]\n",
      "100%|##########| 9.49k/9.49k [00:00<00:00, 1.51MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 16KtxSt_QEGQvfluEaMls5cCHPwhRXgCk\n",
    "!gdown 19L3rYatfhbBL1r5MHrv-p_oM2wlvrhqk\n",
    "!gdown 1OHLKJwA3qZopKPvlKoRldM6BvA1A4dYF\n",
    "!gdown 1N7O_fWCTJLu8SIa_paKcDEzllgpMk8sK\n",
    "!gdown 12Bh2AN8LcZAlg20ehpQrEWccUDaSdsOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lLOv-ppuaas8"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas.core.indexes.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m----> 7\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_sm.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m     10\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas.core.indexes.numeric'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Load data (deserialize)\n",
    "with open('preprocessed_X_sm.pickle', 'rb') as handle:\n",
    "    X_train = pickle.load(handle)\n",
    "\n",
    "with open('X_test.pickle', 'rb') as handle:\n",
    "    X_test = pickle.load(handle)\n",
    "\n",
    "with open('y_sm.pickle', 'rb') as handle:\n",
    "    y_train = pickle.load(handle)\n",
    "\n",
    "with open('y_test.pickle', 'rb') as handle:\n",
    "    y_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0ok3q5zWQIm"
   },
   "source": [
    "\\\n",
    "Earlier, using a DT with max_depth=4,\n",
    "- we were able to obtain the following results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "67NsVcmNUHx8",
    "outputId": "b578e092-9d91-4ed0-8b90-cdbc71e130b5"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_clf = DecisionTreeClassifier(random_state=7, max_depth=4)\n",
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ypl3F1EsVLG5",
    "outputId": "75efb530-dee7-4e7b-a916-53c3bcfdca00"
   },
   "outputs": [],
   "source": [
    "print(\"Train accuracy: {:.2f}\".format(tree_clf.score(X_train, y_train)*100))\n",
    "print(\"Test accuracy: {:.2f}\".format(tree_clf.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruZkpwB3UJ66"
   },
   "source": [
    "In this lecture, we'll look for an approach to improve these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EochCj4CDcq6"
   },
   "source": [
    "## What are Ensemble Models?\n",
    "\n",
    "Till now we have learned about different kinds of models.\n",
    "\n",
    "\\\n",
    "**Do you think we could somehow combine multiple models for the same task?**\n",
    "- This is the key principle of ensembles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBH7oU8aDcrE"
   },
   "source": [
    "<img src='Ensembles.png' height='350' width='600'>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_lFdExCDcrF"
   },
   "source": [
    "### Types of Ensembles\n",
    "\n",
    "There are mainly 4 types of ensemble learning techniques -\n",
    "\n",
    "<img src='Ensembles-2.jpeg' height='350' width='600'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA1hs7_3ZQ8w"
   },
   "source": [
    "```\n",
    "QUIZ:\n",
    "\n",
    "Which one of these is a type of ensemble learning technique?\n",
    "\n",
    "A. Selecting\n",
    "B. Collecting\n",
    "C. Bagging\n",
    "D. Randomizing\n",
    "\n",
    "ANS: C. Bagging\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3D93J6eW_-mv"
   },
   "source": [
    "## What is Bagging?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jgq4u5EFABzh"
   },
   "source": [
    "Bagging simple means **Bootstrapped Aggregating**.\n",
    "\n",
    "\\\n",
    "Let's try to understand this with a simple example:\n",
    "\n",
    "Suppose you want to buy a new iphone,\n",
    "- you aren't sure whether you should or not.\n",
    "\n",
    "\\\n",
    "So you ask your friends & family for opinion.\n",
    "- First person, your friend, is mircoprocessor engineer.\n",
    "- Second person, cousin, works as a cinemetographer.\n",
    "- Third person is your mother.\n",
    "\n",
    "\\\n",
    "<img src='https://drive.google.com/uc?id=1tnYI6u7jNRMFYBEHOBx6i1mKU1QNB-sc' height='450' width='650'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONl5cKFsP3kT"
   },
   "source": [
    "#### What should you do then?\n",
    "\n",
    "Based on the responses that we got,\n",
    "- We can take **majority vote**.\n",
    "  - 2 yes\n",
    "  - 1 no\n",
    "  - results in a YES.\n",
    "\n",
    "\\\n",
    "This is what **bagging** does.\n",
    "\n",
    "\\\n",
    "In short,\n",
    "\n",
    "- **Bagging refers to training different models for the same task,**\n",
    "- **independent of each other and then smartly combining their predictions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0ZwD4pIPcGX"
   },
   "source": [
    "\\\n",
    "Let's take another example.\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1UDAO5pgBS6FJUKQnv85GyZGIYDj9ZxNV' height='450' width='650'>\n",
    "\n",
    "How did we combine the predictions in this case?\n",
    "- We took an **average** of the predicted scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RyXudRiEk1z6"
   },
   "source": [
    "## Can we make an Ensemble from DTs?\n",
    "\n",
    "Yes!\n",
    "\n",
    "**Random Forest (RF)** is a successful method based on Bagging and Decision Trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LoQC9NxL4Ai"
   },
   "source": [
    "By **forest**, we definitly understand a **collection of decision trees**.\n",
    "\n",
    "\\\n",
    "#### But what does the term **'random'** means in RF?\n",
    "\n",
    "It means,\n",
    "- Each tree is trained on a random subset of\n",
    "  - rows ($d'$) and\n",
    "  - columns ($m$).\n",
    "\n",
    "\\\n",
    "This is known as\n",
    "- **Row Sampling** (R.S) and\n",
    "- **Column Sampling** (C.S)\n",
    "\n",
    "\\\n",
    "<img src='https://drive.google.com/uc?id=1YXMDVsSVRNRiR1USo8j_9m8IEokp20Ls' height='300' width='650'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWM24pL-WiP6"
   },
   "source": [
    "```\n",
    "QUIZ:\n",
    "\n",
    "A random forest consists of..?\n",
    "\n",
    "A. A single decision tree\n",
    "B. Multiple decision trees\n",
    "C. Could be both\n",
    "\n",
    "ANS: B. Multiple decision trees\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpgKZyAZlzhA"
   },
   "source": [
    "### How to use multiple DTs together?\n",
    "\n",
    "\\\n",
    "Let's assume we have a dataset $D$ with,\n",
    "- $n$ records and\n",
    "- $d$ features.\n",
    "\n",
    "\\\n",
    "We sample,\n",
    "  - $m_1$ data points (with replacement)\n",
    "  - $d'$ columns\n",
    "to get the dataset $D_1$.\n",
    "\n",
    "Repeat the same,\n",
    "  - $k$ times and we get $D_k$.\n",
    "\n",
    "Train $k$ different base learners i.e.,   \n",
    "  - ($M_1,M_2,..M_k$) on these $k$ datasets.\n",
    "\n",
    "\\\n",
    "At the end, we perform **Aggregation**.\n",
    " * We use majority vote for Classification.\n",
    " * We use Mean/Median for Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vkEhrl4W6Rmz"
   },
   "source": [
    "<img src='https://drive.google.com/uc?id=13VXMenhgAG-XBT7DHVQECwb3q1t-VsOx' height='450' width='700'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hbb2DNDZhc-C"
   },
   "source": [
    "#### But what is the need of adding randomness to a model?\n",
    "\n",
    "Our goal here is that the base learners should be\n",
    "- as different as possible from one another.\n",
    "\n",
    "\n",
    "\\\n",
    "#### Why is it important to make the models **different**?\n",
    "\n",
    "Recall that **iphone** example that we used earlier.\n",
    "\n",
    "\\\n",
    "Suppose,\n",
    "- you ask 3 people who are all iphone fans.\n",
    "\n",
    "If all of them have similar opinions,\n",
    "- the 2 extra people don't add much value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V09TxBEw33N0"
   },
   "source": [
    "```\n",
    "QUIZ:\n",
    "\n",
    "What is the reason for introducing Row/Column Sampling in Random Forests?\n",
    "\n",
    "A. For decreasing the training time of model.\n",
    "B. For tackling the problem of overfitting in base learners.\n",
    "C. For tackling the problem of underfitting in base learners.\n",
    "D. None of the above.\n",
    "\n",
    "ANS: B. For tackling the problem of overfitting in base learners.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHHDSdFPPj8s"
   },
   "source": [
    "## How can we validate RFs?\n",
    "\n",
    "After training, we cross validate each and every base learner.\n",
    "\n",
    "\\\n",
    "We are training,\n",
    "- $k$ different models ($M_1$,$M_2$,...$M_k$) on\n",
    "- $k$ different train sets ($D^1_m$,$D^2_m$....$D^k_m$) respectively.\n",
    "\n",
    "\\\n",
    "<img src='https://drive.google.com/uc?id=13W4H5bNoWFdbi8GHDdJgGZR80Vm7J9Eh' height='350' width='650'>\n",
    "\n",
    "\\\n",
    "The remaining $n-m$ rows can be used as validation data for the model $M^i$.\n",
    "- $D^i_{n-m} = D_n - D^i_m$\n",
    "- This is called Out Of Bag (OOB)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPPM_RvjNISE"
   },
   "source": [
    "Example -\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1h7ROdktkJH7OAhA47OWsxkK_4ILR_zAr' height='350' width='650'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sq8r_6SN3sCM"
   },
   "source": [
    "```\n",
    "QUIZ:\n",
    "\n",
    "If a dataset contains \"n\" rows, and \"m\" of these rows are sampled to train the base learners in Random Forest,\n",
    "what will be the cross-validation data for each of the models?\n",
    "\n",
    "A. Complete dataset with \"n\" rows\n",
    "B. A part of \"m\" sampled rows\n",
    "C. Remaining \"n-m\" rows after sampling\n",
    "\n",
    "ANS: C. Remaining \"n-m\" rows after sampling\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7kml8PmDIYR"
   },
   "source": [
    "#### How to measure the overall performanec of RF?\n",
    "\n",
    "In random forest,\n",
    "- The base learners are validated using the OOB data points.\n",
    "\n",
    "\\\n",
    "But RF as a whole requires,\n",
    "- a cross validation data and\n",
    "- a test data to tune the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0QdOIFsu4dX"
   },
   "source": [
    "## OOB Score\n",
    "\n",
    "We use the left over,\n",
    "- ($n-m$) Out of Bag datapoints\n",
    "- to calculate the **OOB score**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6uCWIobNoHF"
   },
   "source": [
    "#### How to calculate OOB Score?\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1PfexTiZ9OiAlov-unO2rVH79gBf8Mxw-' height='350' width='600'>\n",
    "\n",
    "\\\n",
    "1. Find all models that are not trained on OOB points.\n",
    "  \n",
    "  - In above figure, </br>\n",
    "  <font color= \"offyellow\"> Point C </font> will be OOB point for $M_1$ and $M_3$.\n",
    "\n",
    "2. After training the RF, </br>\n",
    "  - we pass <font color ='offyellow'>Point C</font> through $M_1$ and $M_3$\n",
    "  - and take majority vote/mean of its prediction.\n",
    "\n",
    "3. Then,\n",
    "  - we compare the prediction with\n",
    "  - the actual value of label for <font color ='offyellow'>Point C</font>.\n",
    "\n",
    "\\\n",
    "Similarly, we do this for all the points and calculate the **OOB score**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPPeodWOu7ja"
   },
   "source": [
    "#### When should we use OOB Score?\n",
    "\n",
    "When our dataset is not large enough,\n",
    "- we can't afford to keep a subset for validation.\n",
    "\n",
    "\\\n",
    "So, in that case\n",
    "- RF keep some data aside for each tree.\n",
    "- i.e., the Out of Bag (OOB) datapoints.\n",
    "\n",
    "\\\n",
    "By measuring\n",
    "  - the individual model performance\n",
    "  - on the OOB data points\n",
    "  \n",
    "we can estimate the overall model performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRS6Op2wrT8d"
   },
   "source": [
    "```\n",
    "QUIZ:\n",
    "\n",
    "Fortis has a 15 new samples of patients for a variant of Covid.\n",
    "They use Random Forest to find the fatality rate of the variant.\n",
    "\n",
    "To evaluate the model's performance,\n",
    "\n",
    "1. they should use the OOB data.\n",
    "2. they should use seperate cross validation data.\n",
    "\n",
    "ANS: A. they should use the OOB data.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCJnU_BZBfSf"
   },
   "source": [
    "## Bias Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RkPyNuQYUqy"
   },
   "source": [
    "The base learners in RF are Deep Decision Trees.\n",
    "- So they slightly overfit on the sub sample of data.\n",
    "\n",
    "Which means they have -\n",
    "- low bias\n",
    "- high variance\n",
    "\n",
    "\\\n",
    "#### How do we deal with this issue?\n",
    "\n",
    "We perform **aggregation** on these slightly overfit models.\n",
    "\n",
    "\\\n",
    "#### But how does this reduces variance?\n",
    "\n",
    "Suppose, we have\n",
    "- multiple base learners\n",
    "- with high variance.\n",
    "\n",
    "Let's say the predictions vary by\n",
    "- $\\pm$ 20% around the actual value.\n",
    "\n",
    "When we take average of\n",
    "- predicted values from multiple trees,\n",
    "  - some **+ve errors** will  \n",
    "  - cancel out **-ve errors**.\n",
    "\n",
    "Thus,\n",
    "- we'll be left with smaller residual errors.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rWvECsWaiJP"
   },
   "source": [
    "Example -\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1zaJJ2A_ndYgidvuQNUX5zGlSCd7Tu--G' height='350' width='600'>\n",
    "\n",
    "Only a few samples will contain\n",
    "- the <font color='#F6BE00'>yellow datapoint</font>.\n",
    "\n",
    "Any change in the <font color='#F6BE00'> yellow datapoint</font>,\n",
    "- will only affect handful of base learners.\n",
    "\n",
    "Also,\n",
    "- aggregating the results of all base learners\n",
    "- will negate the impact of noise/outliers.\n",
    "\n",
    "Hence, reducing the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GmPX1ciyEZ1"
   },
   "source": [
    "In statistical Machine Learning,\n",
    "- the error of a model can be represented as:\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1tw2hbU_V3P8Zof5qHCEmSlM5VCF4Z5mt' height='350' width='600'>\n",
    "\n",
    "\\\n",
    "Due to aggregation,\n",
    "- the variance decreases\n",
    "- without trading-off to bias.\n",
    "\n",
    "Therefore,\n",
    "- the overall error of RF reduces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OylVTQ9hDI9v"
   },
   "source": [
    "## Training a RF model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNnr5Y_2X9U0"
   },
   "source": [
    "The base learners in RF can be trivially parallelised.\n",
    "\n",
    "As each models is trained independently,\n",
    "- we can even use distributed computing.\n",
    "\n",
    "Here, each processor can\n",
    "- train several different model,\n",
    "- on different sets of data.\n",
    "\n",
    "\\\n",
    "Due to this,\n",
    "- the training process becomes faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8-Y_mNcE3Fv"
   },
   "source": [
    "```\n",
    "QUIZ:\n",
    "\n",
    "The target attributes in the random forest model indicates the value of?\n",
    "\n",
    "A. Leaf node\n",
    "B. Root node\n",
    "C. Decision node\n",
    "D. None of these\n",
    "\n",
    "ANS: A. Leaf node\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpiXnCjky7IY"
   },
   "source": [
    "**NOTE:** </br>\n",
    "- The time complexity of RF is O($k$ * max_depth of tree)\n",
    "- The space complexity of RF is O(no. of nodes * $k$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdDs8d3f1uq2"
   },
   "source": [
    "## Code Implementation - RF\n",
    "\n",
    "Let's try to train a RF classifier for our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xug930LFQ31E"
   },
   "outputs": [],
   "source": [
    "# Load data (deserialize)\n",
    "\n",
    "with open('preprocessed_X_sm.pickle', 'rb') as handle:\n",
    "    X = pickle.load(handle)\n",
    "\n",
    "with open('y_sm.pickle', 'rb') as handle:\n",
    "    y = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nD4bpPRID2IO"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=7, max_depth=4, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cb0pgWOJt8Un",
    "outputId": "2cf1c9bd-4155-4a18-9bd4-51826f538dac"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "kfold = KFold(n_splits=10)\n",
    "cv_acc_results = cross_validate(rf_clf, X, y, cv=kfold, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "print(f\"K-Fold Accuracy Mean: \\n Train: {cv_acc_results['train_score'].mean()*100:.2f} \\n Validation: {cv_acc_results['test_score'].mean()*100:.2f}\")\n",
    "print(f\"K-Fold Accuracy Std: \\n Train: {cv_acc_results['train_score'].std()*100:.2f}, \\n Validation: {cv_acc_results['test_score'].std()*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xIc26ZWxwA8"
   },
   "source": [
    "As we can see that,\n",
    "- the test accuracy has increased\n",
    "- From **78%** to **84%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PmfUSzfRnjh"
   },
   "source": [
    "## How can further optimize our RF model?\n",
    "\n",
    "Remember hyperparameters?\n",
    "\n",
    "\\\n",
    "Let's see the various hyperparameters of Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h5Ik9k7XvCf"
   },
   "source": [
    "---\n",
    "#### 1. n_estimators - Number of Trees ($k$)\n",
    "- Default=100\n",
    "\n",
    "#### 2. max_samples - Row sample size ($m$)\n",
    "- Default=None, draws all samples.\n",
    "- Otherwise, should be in the interval (0.0, 1.0]\n",
    "\n",
    "#### 3. max_features - Number of columns sampled ($d'$)\n",
    "- Can be {“sqrt”, “log2”, None}\n",
    "  - If “sqrt”, then max_features=sqrt(n_features).\n",
    "  - If “log2”, then max_features=log2(n_features).\n",
    "  - If None, then max_features=n_features.\n",
    "- Default=\"sqrt\"\n",
    "\n",
    "<img src='https://drive.google.com/uc?id=1z-W6O1-fKu4BWm8_ZL17ZNS6-6bzdqY9' height='350' width='650'>\n",
    "\n",
    "#### 4. max_depth - Depth of Base Learners\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2hfjQz__RNX"
   },
   "source": [
    "#### 5. ccp_alpha - cost complexity pruning ($α$)\n",
    "\n",
    "Similar to $λ$,\n",
    "- which we used in linear & logistic regression\n",
    "\n",
    "for regularization.\n",
    "\n",
    "`ccp_alpha` is used to simplify DTs in a Random Forest.\n",
    "\n",
    "\\\n",
    "Since our aim is to find a balance between performace and complexity,\n",
    "\n",
    "\\\n",
    "- We start with building a detailed tree.\n",
    "- Then assign a cost to each additional branch or leaf.\n",
    "- And gradually removes branches and leaves\n",
    "  - contributing the least towards model's performace.\n",
    "\n",
    "\\\n",
    "As $α$ increases,\n",
    "- more of the tree is pruned,\n",
    "- thus creating a generalized model\n",
    "- and prevent overfitting.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORVjEX1wjiwR"
   },
   "source": [
    "There are other hyperparameters too in a RF.\n",
    "\n",
    "Most of them are same ones that we saw in DT.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "\\\n",
    "<center><img src='https://drive.google.com/uc?id=1vjUu4h9HLJhVvBg86dO9mV6vO-NW7OAT' height='225' width='950'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uie8_DEf6ZuW"
   },
   "source": [
    "```\n",
    "QUIZ:\n",
    "\n",
    "Which one of the following in not a hyperparameter of Random Forest?\n",
    "\n",
    "A. Number of base learners\n",
    "B. Depth of base learners\n",
    "C. Sample size\n",
    "D. Total number of columns\n",
    "\n",
    "ANS: D. Total number of columns\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkkIM4uW7dj_"
   },
   "source": [
    "```\n",
    "QUIZ:\n",
    "\n",
    "What is the use of the hyperparameter 'ccp_alpha'?\n",
    "\n",
    "A. To set the column sampling ratio\n",
    "B. To control underfitting or overfitting\n",
    "C. To optimize the learning rate of RF\n",
    "D. To set the depth of the base learners\n",
    "\n",
    "ANS: B. To control underfitting or overfitting\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FkCl3Y4QWtz"
   },
   "source": [
    "## How do we tune these hyperparameters?\n",
    "\n",
    "#### Grid Search\n",
    "\n",
    "- We specify a range of values for each hyperparameters.\n",
    "- And try every possible combination of those values,\n",
    "- Until we find the one with optimal performance.\n",
    "\n",
    "\\\n",
    "<img src='https://drive.google.com/uc?id=1ZO4IXZp3MMqvHB4TG0EZ0LDmM-i6CV1a' height='350' width='600'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b2cJiP7n5FJJ"
   },
   "outputs": [],
   "source": [
    "# Defining parameters -\n",
    "\n",
    "params = {\n",
    "          'n_estimators' : [100,200,300,400],\n",
    "          'max_depth' : [3,5,10],\n",
    "          'criterion' : ['gini', 'entropy'],\n",
    "          'bootstrap' : [True, False],\n",
    "          'max_features' : [8,9,10]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foLLZtRy6lPG"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid = GridSearchCV(estimator = RandomForestClassifier(),\n",
    "                    param_grid = params,\n",
    "                    scoring = 'accuracy',\n",
    "                    cv = 3,\n",
    "                    n_jobs=-1\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_U60eg3h7Hel",
    "outputId": "67634b97-accb-4f92-f47d-6c80a893d0dd"
   },
   "outputs": [],
   "source": [
    "grid.fit(X, y)\n",
    "\n",
    "print(\"Best params: \", grid.best_params_)\n",
    "print(\"Best score: \", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpuTXjGRW-MS",
    "outputId": "4fc32d24-045e-4fe5-844e-eb7e2e0ba09e"
   },
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier(random_state=7, bootstrap=False, criterion='gini',\n",
    "                              max_depth=10, max_features=8, n_estimators=200)\n",
    "\n",
    "kfold = KFold(n_splits=10)\n",
    "cv_acc_results = cross_validate(clf2, X, y, cv=kfold, scoring='accuracy', return_train_score=True)\n",
    "\n",
    "print(f\"K-Fold Accuracy Mean: \\n Train: {cv_acc_results['train_score'].mean()*100:.3f} \\n Validation: {cv_acc_results['test_score'].mean()*100:.3f}\")\n",
    "print(f\"K-Fold Accuracy Std: \\n Train: {cv_acc_results['train_score'].std()*100:.3f}, \\n Validation: {cv_acc_results['test_score'].std()*100:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMBPoUjL73he"
   },
   "source": [
    "#### Are there any cons of using Grid Search?\n",
    "\n",
    "- Let's say there are 7 hyperparameters and\n",
    "- each hyperparameter has 5 possible values.\n",
    "\n",
    "\\\n",
    "Using Grid Search,\n",
    "- no. of combinations tried will be $5^7$,\n",
    "- which is 78125.\n",
    "\n",
    "\\\n",
    "Grid Search performs really well for dataset with less dimensions.\n",
    "\n",
    "However, it explores all possible combinations, </br>\n",
    "which can be\n",
    "- computationally expensive\n",
    "- time-consuming\n",
    "\n",
    "for higher dimension datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jTQQWweVI1W"
   },
   "source": [
    "```\n",
    "QUIZ:\n",
    "\n",
    "If for Grid Search, there are 4 hyperparameters each having 10 values.\n",
    "Then what will be the total possible combinations?\n",
    "\n",
    "A. 10000\n",
    "B. 1000\n",
    "C. 100000\n",
    "D. 9999\n",
    "\n",
    "ANS: A. 10000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Ov5EwjJViIz"
   },
   "source": [
    "```\n",
    "QUIZ:\n",
    "\n",
    "If you’re performing GridSearchCV on a random forest model for the parameters,\n",
    "- ‘max_depth’ having 3 values and\n",
    "- ‘min_samples’ having 4 values\n",
    "- for 10 cross-validations\n",
    "\n",
    "How many times model.fit() is called?\n",
    "\n",
    "A. 1440\n",
    "B. 120\n",
    "C. 40\n",
    "D. 30\n",
    "\n",
    "ANS: B. 120\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rrhqd89F-oPu"
   },
   "source": [
    "### Do we a better option than this?\n",
    "\n",
    "#### Randomized Search\n",
    "\n",
    "- This will try random combinations of hyperparameters\n",
    "- from a finite list of options or from a distribution.\n",
    "\n",
    "\\\n",
    "It is better to use Randomized Search </br>\n",
    "when we're dealing with,\n",
    "- large hyperparameter space\n",
    "- limited computational resources\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xh4FWYwA8yM"
   },
   "source": [
    "Let's try finding the optimal value of `ccp_alpha` for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-QZtwZB-scT"
   },
   "outputs": [],
   "source": [
    "# Defining parameters -\n",
    "\n",
    "from scipy.stats import uniform\n",
    "\n",
    "params = {'ccp_alpha': uniform(loc=0, scale=0.4)}\n",
    "# sample from uniform dist between 0 to 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcN9Z-VLBIRb"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random = RandomizedSearchCV(estimator = RandomForestClassifier(random_state=7, bootstrap=False, criterion='gini',\n",
    "                                                               max_depth=10, max_features=8, n_estimators=200),\n",
    "                            param_distributions = params,\n",
    "                            scoring = 'accuracy',\n",
    "                            cv = 3,\n",
    "                            n_iter=15,\n",
    "                            n_jobs=-1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNoF4TN7BJk9",
    "outputId": "a2dd3440-207e-4a24-987e-a48caf50cced"
   },
   "outputs": [],
   "source": [
    "random.fit(X, y)\n",
    "\n",
    "print(\"Best param: \", random.best_params_)\n",
    "print(\"Best score: \", random.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4m7n9TGb-ucD"
   },
   "source": [
    "#### What are the benefits of Randomized Search?\n",
    "\n",
    "Randomized Search,\n",
    "- samples a subset of combinations.\n",
    "\n",
    "Hence,\n",
    "- reducing the search space and\n",
    "- allowing for faster exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AT7Y8R9act-o"
   },
   "source": [
    "## How to compute Feature Importances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDaT9zRiidof"
   },
   "source": [
    "#### How does Feature Importance in a RF work?\n",
    "\n",
    "A simple way of this is\n",
    "- Compute importance of a feature in each DT\n",
    "- Then take the average of these values.\n",
    "\n",
    "\\\n",
    "#### What if some base learners don't have that feature?\n",
    "\n",
    "\\\n",
    "Let's say in a RF,\n",
    "- there are 100 trees (base learners)\n",
    "- column sampling rate is 0.1\n",
    "\n",
    "\\\n",
    "A feature $f_1$  \n",
    "- will approximately be in 10 base learners.\n",
    "- same happens with all other features too.\n",
    "\n",
    "\\\n",
    "Some of the trees won't have the feature $f_1$.\n",
    "\n",
    "In that case,\n",
    "- the importance of that missing feature in the base learner is zero.\n",
    "\n",
    "\\\n",
    "**The presence of multiple decision trees compensates for the absence of certain features in individual trees.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0o-YU6-Chash",
    "outputId": "d247bf7f-ef8b-455f-9902-e66bd1f6b9d6"
   },
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rf_clf.fit(X, y)\n",
    "importances = rf_clf.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1] # Sort feature importances in descending order\n",
    "names = [X.columns[i] for i in indices] # Rearrange feature names so they match the sorted feature importances\n",
    "\n",
    "plt.figure(figsize=(15, 7)) # Create plot\n",
    "plt.title(\"Feature Importance\") # Create plot title\n",
    "plt.bar(range(X.shape[1]), importances[indices]) # Add bars\n",
    "plt.xticks(range(X.shape[1]), names, rotation=90) # Add feature names as x-axis labels\n",
    "plt.show() # Show plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uK8QdyW7zJnQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
