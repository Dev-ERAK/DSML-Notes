{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJhSvwU5jJvc"
   },
   "source": [
    "## Content\n",
    "- Pseudo Residual for log loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1Q47wv5GVJm"
   },
   "source": [
    "## Pseudo Residual for log loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1T-CT6D2O639"
   },
   "source": [
    "To show that the negative of the derivative of the loss function (log-loss) is psuedo residual [$-(\\frac{d(L^{log})}{d(F_k(x_i))})$] which is similar to the residual (difference between actual and predicted values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gBzOm6QG4rt"
   },
   "source": [
    "Let us assume our loss function be Log-loss and our problem is a binary classification problem\n",
    "* The output of the $k_{th}$ model $F_k(x_i) = p_i = p((y_i=1)|x_i)$ that is probability of $y_i$ being 1, given $x_i$\n",
    " * where $y_i$ is the actual class label\n",
    "\n",
    "\n",
    "We know the **loss function is log loss**\n",
    "   * $L = logloss(y_i,p_i) = y_i log p_i + (1-y_i) log(1-p_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8aoIc_KIvfZ"
   },
   "source": [
    "Therefore,\n",
    "* $-(\\frac{\\partial L(y_i,p_i)}{\\partial(p_i)})  = -\\frac{∂([y_i log p_i + (1-y_i) log(1-p_i))}{∂p_i}$\n",
    "\n",
    "Using  product rule,\n",
    "\n",
    "$\\frac{\\partial L(y_i,p_i)}{\\partial(p_i)} = y_i.\\frac{∂(logp_i)}{∂p_i} + logp_i.\\frac{∂(y_i)}{∂p_i} + (1 - y_i)\\frac{∂(log(1 - p_i))}{∂p_i} + log(1-p_i). \\frac{∂(1-y_i)}{∂p_i} $\n",
    "\n",
    "$y_i$ is constant when we take derivative w.r.t $p_i$\n",
    "\n",
    "<br>\n",
    "\n",
    "The derivative comes out to be\n",
    "\n",
    "$- \\frac{\\partial L(y_i,p_i)}{\\partial(p_i)} = -[\\frac{y_i}{p_i} - \\frac{1-y_i}{1-p_i}] = \\frac{p_i(i-y_i) - y_1(1-p_i)}{p_i(1-p_i)}$\n",
    "\n",
    "<br>\n",
    "\n",
    "so,\n",
    " $-(\\frac{dL}{d(p_i)}) = -\\frac{y_i-p_i}{p_i(1-p_i)}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YE80GgSbMUzu"
   },
   "source": [
    "* Here the numerator is capturing the difference which is the $(y_i - \\hat{y}_i)$ which is key a\n",
    "- Consider denomination $p_i(1 - p_i)$ as a normalizing factor\n",
    "* Hence proved that the when we use log-loss the psuedo residual behaves like a residual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5jRNH5bLf5u"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "<center><img src='Log-loss.png' width=700></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoH8g13TL81U"
   },
   "source": [
    "<center><img src='prod-rule.png' width=700></center>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pt75eiLfMFTB"
   },
   "source": [
    "<center><img src='derivative.png' width=700></center>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
