{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5dNRgHATK_PV"
   },
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8IuPvF_f8F4f"
   },
   "source": [
    "- **Bagging recap**\n",
    "\n",
    "- **Boosting Introduction**\n",
    "    - Quiz 1 -2\n",
    "    - [What does Boosting do?](https://www.scaler.com/hire/test/problem/16856/)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "- **Boosting Intuition - How do we combine base learners ?**\n",
    "    - Residual\n",
    "    - Geometrical Intuition\n",
    "    - Quiz 3 - 7\n",
    "    - [Random Forest vs Boosting](https://www.scaler.com/hire/test/problem/16849/)\n",
    "    - [Additive Combinations](https://www.scaler.com/hire/test/problem/25996/)\n",
    "    - [Random Forest and Gradient Boosting](https://www.scaler.com/hire/test/problem/26069/)\n",
    "    - [First Prediction](https://www.scaler.com/hire/test/problem/25975/)\n",
    "    - [Bagging or Boosting](https://www.scaler.com/hire/test/problem/25974/)\n",
    "\n",
    "\n",
    "- **What happens at train and test time ?**\n",
    "\n",
    "- **Why Boosting ? - GBDT Intuition**\n",
    "    - Pseudo residual\n",
    "    - Quiz 8 - 9\n",
    "    - [Gradient boosting Pseudo Residuals](https://www.scaler.com/hire/test/problem/17954/) h/w\n",
    "\n",
    "\n",
    "- **Sklearn implementation**\n",
    "    - Quiz 10\n",
    "    - [Gradient Boosting Classifier](https://www.scaler.com/hire/test/problem/25971/) (coding)\n",
    "    - [Gradient boosting fit](https://www.scaler.com/hire/test/problem/25962/) (coding) h/w\n",
    "    - [Max_depth and min_samples](https://www.scaler.com/hire/test/problem/26004/) h/w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rlvQ_c96ler"
   },
   "source": [
    "## Bagging recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbeU6G45vrz0"
   },
   "source": [
    "#### What did we do in Bagging?\n",
    "\n",
    "We had base learners which were\n",
    "- low bias\n",
    "- high varianace\n",
    "\n",
    "\\\n",
    "#### How did we reduced the variance ?\n",
    "\n",
    "We performed\n",
    "- randomization i.e. **row & column sampling**.\n",
    "\n",
    "And finally\n",
    "- **aggregated** these learners together.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjfcVaVnvpr8"
   },
   "source": [
    "## Boosting Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFsLQgc75lhP"
   },
   "source": [
    "On the other hand, in boosting, we again have **base learners**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s20XY12G6rrn"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "#### So, what's the nature of base learners in boosting ?\n",
    "\n",
    "Here the learners are\n",
    "- **high bias and low variance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_Og5WAV8OBw"
   },
   "source": [
    "```\n",
    "Quiz 1 - Check your understanding\n",
    "\n",
    "\n",
    "Typically, high bias low variance models are:\n",
    "a. Overfit\n",
    "b. Underfit\n",
    "c. Best fit\n",
    "\n",
    "Correct option: b. Underfit\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAiJy_Wm8fxu"
   },
   "source": [
    "Now, that we have base learners, we need something to combine them.\n",
    "\n",
    "#### Do you think we can use randomization and aggregation to combine these learners ?\n",
    "\n",
    "No.\n",
    "\n",
    "Recall that\n",
    "    \n",
    "    Randomization was used in bagging in order to reduce the variance\n",
    "\n",
    "Here, variance is already low.\n",
    "\n",
    "    Goal: We have to reduce the bias\n",
    "\n",
    "\n",
    "\n",
    "#### So, how do we combine these learners and reduce the bias ?\n",
    "\n",
    "We use something called **additive combination**\n",
    "\n",
    "Let's see how we combine them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XOufWAWA9hJk"
   },
   "source": [
    "```\n",
    "Quiz 2 - Try it out\n",
    "\n",
    "\n",
    "Which of the following model are underfit models ?\n",
    "\n",
    "a. Decision Stump (Decision Tree with depth = 1)\n",
    "b. Decision Tree with depth = 20\n",
    "c. Decision Tree with depth = 10\n",
    "d. None of the above.\n",
    "\n",
    "Correct option: a. Decision Stump\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUfN_O7wHyPU"
   },
   "source": [
    "## Boosting Intuition - How do we combine base learners ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQx54nRqH_Ak"
   },
   "source": [
    "\n",
    "Remeber that,\n",
    "\n",
    "The **core idea** is\n",
    "- we have **high bias low variance** base learners.\n",
    "\n",
    "and we have to **reduce the bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yC5YldaJnn8"
   },
   "source": [
    "Let's understand how we do this using an example.\n",
    "\n",
    "\n",
    "For simplicity, we'll use an **regression example**\n",
    "- i.e. **target variable** will be numerical/**continuous**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bu7QqBVzKhVn"
   },
   "source": [
    "Say, we have a regression problem where\n",
    "- **given** the **weight** and **gender** of person\n",
    "- we have to **predict** the **height** of the person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bodh-Dv3NQ5b"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1UZR-pIJbsO5OdtKad_L5h3T6XrZliy97' width=700></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWSjNnQ6XMuH"
   },
   "source": [
    "On this training data ($D_{Train}$), we build our model in steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RzKm2F5MX-v"
   },
   "source": [
    "### Step 0 : $M_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vujDQjsOMZk8"
   },
   "source": [
    "We use this training data\n",
    "- and **build a model $M_0$** on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OL_ZV5qSOp7B"
   },
   "source": [
    "\n",
    "\n",
    "Note that, this model has to be **high bias low variance** model i.e. **simplest model**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n82DqMcoSwHE"
   },
   "source": [
    "```\n",
    "Quiz 3 - What model will have high bias low variance ? (Hint: think of simplest model)\n",
    "\n",
    "\n",
    "a. Mean model (which predict mean value everytime)\n",
    "b. Random model (model which predicts random value everytime)\n",
    "c. A DT fit perfectly on training data\n",
    "\n",
    "Correct option: a. Mean model\n",
    "\n",
    "Explanation:\n",
    "- Mean model will have high bias and low variance\n",
    "- Random model will have high bias high variance.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXJ4FzwkT3iM"
   },
   "source": [
    "So, we use **Mean Model**\n",
    "- i.e. take the **average** of **y values** given to us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1bLoaaTKU_ca"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=17INR8oKMa_foHcobDEkimN-KxfYi1KnA' width=500></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-X3cUhVWdfR"
   },
   "source": [
    "Let's represent the prediction using $h_0(x)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CADW9O7PbE6o"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=15Ei-54hye3-ikxvnzNQ4NqaypZratpLj' width=500></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8moS71ycz9L"
   },
   "source": [
    "Now, there'll be some error associated with these predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zM2VOHeodNfs"
   },
   "source": [
    "```\n",
    "Quiz 4 - Try it out\n",
    "\n",
    "What will be the training error for high bias model ?\n",
    "\n",
    "a. High error\n",
    "b. No error\n",
    "c. Low error\n",
    "\n",
    "\n",
    "Correct option: a. High error\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jPzZXe0dgz_"
   },
   "source": [
    "Since, it is a **mean model**,\n",
    "- it'll have **large training error**\n",
    "\n",
    "\n",
    "After building the model,\n",
    " - we calculate these error/ residual\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCBudVWyeDyh"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1dUoUFdpmxKTQRofTStXgh7HNdRrGYcNe' width=700></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCNKe60GeOjM"
   },
   "source": [
    "Using this,\n",
    "\n",
    "- we can represent actual value ($y^{i}$) as. :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijE1xpZChKZh"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=16oWLjRmzFs3MeQ8cXV68CWQSy2mrKU5p' width=600></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_u_jbXfpZukk"
   },
   "source": [
    "i.e.  **combination of prediction and error.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nNBZMpGZ0gT"
   },
   "source": [
    "#### What is our goal ?\n",
    "\n",
    "We want to improve our prediction by reducing the error.\n",
    "\n",
    "In order to do so,\n",
    "\n",
    "#### **What if we fit a new model to predict the error and add that prediction to original prediction ($h_0(x)$) ?**\n",
    "\n",
    "\n",
    "This is what we do in next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zU6o0sgrbuEo"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1497YY5EvjAqUKZNnZ9Z3ZMV-KWycBIYX' width=600></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EI8JmK6kcmkK"
   },
   "source": [
    "#### How would predicting the error help in reducing it ?\n",
    "\n",
    "Suppose we predicted the error\n",
    "- and the prediction came out to be $e_{pred}$\n",
    "\n",
    "\n",
    "So, the total prediction will be\n",
    "- $h_0(x^i) + e_{pred}$\n",
    "\n",
    "Note that\n",
    "- this total prediction will be much closer to the actual prediction\n",
    "\n",
    "So,\n",
    "- we are reducing the error when we predict the error and add that prediction to previous prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xB4NK2fGaAAc"
   },
   "source": [
    "### Step 1 : $M_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_PRiV3iJZ_X3"
   },
   "source": [
    "We take the {$x^i, err^i_0$} from the previous step and\n",
    "- fit a model on it.\n",
    "\n",
    "\n",
    "Let's call this model $M_1$\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Which model shall we use as $M_1$ ?\n",
    "\n",
    "Generally, it can be any model (be linear regression etc)\n",
    "- but since we are talking about boosted decision trees\n",
    "- so, we'll consider a **decision tree** over here\n",
    "\n",
    "Remember that\n",
    "- **Decision Tree** used here will be of **low depth**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_AUJzcHc0-M"
   },
   "source": [
    "```\n",
    "Quiz 5 - Try it out\n",
    "\n",
    "Why are we using DT with low depth here ?\n",
    "\n",
    "a. we are looking for high variance low bias model\n",
    "b. we are looking for high bias low variance model\n",
    "c. we are looking for overfit model\n",
    "d. no reason. just picked it randomly.\n",
    "\n",
    "Correct option: b. we are looking for high bias low variance model\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NbUCIj0esy4"
   },
   "source": [
    "**Low depth** model will be **high bias and low variance models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGlRsmEhezDp"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1a_vHw6XGQPj2hhDrvOexDsH8DLPW5TQ-' width=800></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c_2UAg5Zhxlz"
   },
   "source": [
    "The prediction of this model is represented using $h_1(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRDrBzEriDCx"
   },
   "source": [
    "Now, we need to add Step 1's prediction with Step 0's prediction\n",
    "\n",
    "This is what **additive combination** is called."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY51SF5FiNHP"
   },
   "source": [
    "The final model $F_1(x)$ at the end of step 1 is defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Om6ZeO5DkPFj"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1pmPoYRvKE9__R3pEfSd0UTuMl6l5CN_k' width=700></center>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBPR5zEvm4cR"
   },
   "source": [
    "#### Issues with simple addition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09xO14kIoXXf"
   },
   "source": [
    "There's a **possibility** that\n",
    "- model trained at **stage 1 has large residuals**\n",
    "- and **isn't contributing** much to the final prediction\n",
    "\n",
    "So, we **need** to have a **mechanism** which\n",
    "- defines how much of **model contribution** do we want to add **to final model predicition**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rg1lWtHjpJsv"
   },
   "source": [
    "#### How do we resolve this issue ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TReDhcFnpMWE"
   },
   "source": [
    "**Instead** of using simple addition,\n",
    "- **multiply** the model with a **weight value** (γ)\n",
    "\n",
    "\n",
    "If the model has **lower residual**,\n",
    "- then we'll have **large weight** assign to it\n",
    "- i.e. **more influence** to final predicition\n",
    "\n",
    "If the model has **higher residual**\n",
    "- then we'll **reduce its infludence** by assigning it **small weight**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "241hrqxJqNqK"
   },
   "source": [
    "#### How do we learn these weights ?\n",
    "\n",
    "We do so using optimization (will be discussed later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EuiQQF9rp9s0"
   },
   "source": [
    "So, the final model prediction @ stage 1 becomes :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSqx4cIWqNFL"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=14_OC9qz7rOJT3ESgqhGO29zleliWqv0y' width=700></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqRWN9VYqmWm"
   },
   "source": [
    "But, we don't stop here.\n",
    "\n",
    "We move onto next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHMCW7-8rT16"
   },
   "source": [
    "### Step 2: $M_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JqxiQrACrV6G"
   },
   "source": [
    "\n",
    "For stage 2,\n",
    "\n",
    "- we also train the model on residual i.e.\n",
    "\n",
    "- {$x^i, err^i$}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeBAWIGYxFRX"
   },
   "source": [
    "#### What will be residual used in step 2 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msipnvYeuz2h"
   },
   "source": [
    "```\n",
    "Quiz 6 - Check your understanding\n",
    "\n",
    "What error shall we use here at stage 2 ?\n",
    "\n",
    "\n",
    "a. Residual left after subtracting final model prediction\n",
    " (F_1(x)) from actual value\n",
    "b. Residual left after subtracting Stage 1 model (M_1) from actual value\n",
    "c. Residual left after subtracting Stage 0 model (M_0) from actual value\n",
    "d. None of the above\n",
    "\n",
    "\n",
    "Correct option: a. Residual left after subtracting final model prediction  (F_1(x)) from actual value\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30Ud-p4dwDtP"
   },
   "source": [
    "Here,\n",
    "- $err^i$ will be $err^i_1$\n",
    "- i.e. residual left after Stage 1 final model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68lqlnPjwTNa"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1klWmUbMSEFRRe_k43WSAjMq9z0INXfO5' width=700></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fx5TrCUJxTWg"
   },
   "source": [
    "Now, using this {$x^i, err^i_1$}\n",
    "- we again **train a model** (say, $M_2$)\n",
    "- i.e. a DT with small depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OONItezMx1Or"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1HXbhoiEMsot00eaC1OcWXYByIJ9ObsFs' width=800></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZMNc20Jz76k"
   },
   "source": [
    "The final prediction at the end of step 2 will be :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJUwMnER0cNy"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1jSATsUVoOldtevpKXZs3McQjXRzsSmJW' width=800></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg0N3XpK1DE1"
   },
   "source": [
    "If we keep doing this till M steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l3U7N78q1kDK"
   },
   "source": [
    "### Step M :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAzl89W41t1Q"
   },
   "source": [
    "The final model @ end of stage M will be :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGq4uUIP1y_d"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1Q74iZo3XCr1vOC4sXix8JrlL2bJRT9iK' width=800></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uioditSc4b61"
   },
   "source": [
    "Here **M is the number of models (base learners)**\n",
    "- It can be 100, 200 or 300 etc\n",
    "- i.e it is a **hyperparameter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feVWCgqP207D"
   },
   "source": [
    "To **conclude**:\n",
    "\n",
    "- we are **iteratively** building our **models** on the **error of the previous models**.\n",
    "- i.e. it is a sequential technique\n",
    "- Each model is high bias low variance model\n",
    "- We use weights to adjust the influence of model in final prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtQeILiS3Itm"
   },
   "source": [
    "```\n",
    "Quiz 7 - Check your understanding\n",
    "\n",
    "Which of the following statement is true?\n",
    "\n",
    "a. Boosting is a sequential model building technique\n",
    "b. We use weights to adjust the influence of model in final predicition\n",
    "c. New model is build on the error of previous models\n",
    "d. All of the above\n",
    "\n",
    "\n",
    "Correct option: All of the above.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bnl4eQao3pvo"
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JkWwkW25WK9"
   },
   "source": [
    "Let's recap the process using an example\n",
    "\n",
    "- Predicting the weight using height and gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UWBNq905bo1"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1UZR-pIJbsO5OdtKad_L5h3T6XrZliy97' width=700></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwOLtPji5g8f"
   },
   "source": [
    "We start off with stage 0\n",
    "\n",
    "- where the prediction will be average of all values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7U70LiT5qeM"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1tX2E9YyhobXfRpzycmQuGDa10FJ01j-n' width=700></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8dQFFIh6YEX"
   },
   "source": [
    "Now, using the prediction of stage 0\n",
    "- we calculate the residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZdfcdIC6ghZ"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=12VngbawGHJm6W5YVb3EbythzWS6guuD5' width=700></center>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQRHTtBy7div"
   },
   "source": [
    "Now, we use the features (height , gender) and these error value to fit a new model to it\n",
    "- i.e. Stage 1 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwbNSFDq7dgr"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1D7Mr1DTd2dkUbM6_Ie7woH8QmrIOj_EJ' width=700></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n7VmvENL7acn"
   },
   "source": [
    "Then we calculate the final predicition\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAj5mPOk-pbe"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1QjwxfYxScmTKRaKfTYkZV10y9zksBazI' width=700></center>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7Ev5yVPAIGL"
   },
   "source": [
    "followed by calculating error i.e. (y - final prediction @ end of stage 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsXX-IJOADdj"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=17wMxUkTq_Jr88VPNsa0wbsyrKYfE15kf' width=700></center>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EJ9Qcuy-uJT"
   },
   "source": [
    "\n",
    "This process goes on till M steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_WG2Q_QFrD-"
   },
   "source": [
    "### Geometrical Intution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYjDuVsfFzjG"
   },
   "source": [
    "#### How does model fitting looks like geometrically ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPmUnz_NF35c"
   },
   "source": [
    "Imagine we have 2D regression data which looks like :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5biLy8OGB1V"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1aar45UOa-XOUqykyDsrNxy8Mobepw7HO' width=700></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KO9YMUepGXPt"
   },
   "source": [
    "The regression line after each model stage will look like :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3Z3kAdqGhSQ"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1vr-XTgG7DNAuDCNTVs7oTFnp0ejLXNUC' width=700></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTBdSKe7GjfX"
   },
   "source": [
    "Notice that\n",
    "- how it starts from a straight line (mean model)\n",
    "- and adds on the complexity as iteration (Steps) increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-zq2zS3GwYv"
   },
   "source": [
    "The whole process along with the reduction in residual looks as follows :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BGjNvPNSG25y"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1uAPBbE0PORxg3K_UUJuYpVMTxaWwavJL' width=700></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qt3uckNaG50T"
   },
   "source": [
    "Notice that\n",
    "- as we add the stage K's prediction to the final prediction\n",
    "    - the regression like fits better to the data\n",
    "- also the residual is reducing for each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOixy3QKJHjH"
   },
   "source": [
    "## What happens at train and test time ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elMXaR0PJKNr"
   },
   "source": [
    "#### At train time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "623aHZpzJMjR"
   },
   "source": [
    "\n",
    "- it fits all the decision trees\n",
    "- and find the value of weights (γ)\n",
    "\n",
    "\n",
    "\n",
    "Recall that\n",
    "- the model were **trained** **iteratively** on the error of previous model\n",
    "\n",
    "- i.e. **kth model** is **trained** only **after k-1 th** model is done with the training\n",
    "- it is a **sequential** **process**\n",
    "\n",
    "Hence, **training** is bit **slow**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCn9yu_MJhkh"
   },
   "source": [
    "#### At test time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCHQ56cNJ8qz"
   },
   "source": [
    "Say, we found out M = 3 as best hyperparam\n",
    "\n",
    "So, final prediction will be :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VklQQj6pKKZz"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1m3NA4Uono3Dh3MKN9qN9IyHodI0Rjgio' width=700></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCh6f922Knjk"
   },
   "source": [
    "We have already found out of the values of $h_0(x), h_1(x) ... h_3(x)$\n",
    "- these are nothing but Decision Trees\n",
    "\n",
    "- We also find the weights ($γ_1, γ_2, γ_3$) during the training time.\n",
    "\n",
    "So, for a query point\n",
    "- we just need to pass it thorugh the DTs and get the prediction\n",
    "- and multiply it with the weight values (which were calculated at train time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFZNEmoQL_Ah"
   },
   "source": [
    "## Why Boosting ? - Gradient Boosting Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viGKWWqeN9uh"
   },
   "source": [
    "```\n",
    "Quiz 8 - Try it out\n",
    "\n",
    "\n",
    "True or False: We can parallelize boosting process i.e. build each model parallely\n",
    "\n",
    "a. True\n",
    "b. False\n",
    "\n",
    "\n",
    "Correct option: False\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlGZ8f9hOdN8"
   },
   "source": [
    "Since each subsequent model depends upon\n",
    "- the error of the previous model\n",
    "\n",
    "It is **impossible** to **parallelize** the process.\n",
    "- So, it'll be slower than RF.\n",
    "\n",
    "#### We already have Random forest which can be easily be parallilized. Why do we need boosting then ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB_psbAdO5ct"
   },
   "source": [
    "The real magic of boosting lies in the fact that\n",
    "- **it can minimize any loss**\n",
    "\n",
    "\n",
    "Be it squared loss, logloss\n",
    "- we can minimize it using **gradient boosting**\n",
    "\n",
    "Let's see how boosting does that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EvuHL_L_rJX"
   },
   "source": [
    "### Pseudo residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykdlStRs_tXm"
   },
   "source": [
    "Say, we want to minimize the squared loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob-IGNFXAeCx"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1xep9g-StbvgmmtYxDzmMFQs-PNlSoPd-' width=700></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrkSJX1rBSM6"
   },
   "source": [
    "Let's **differentiate** the **loss** function **w.r.t** **ŷ** (output of the model)\n",
    "\n",
    "The differentiation will come out to be :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljg64jrlB26j"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1aGQE6W8NDoqGd-jMrbumV8lneEKJG1xh' width=700></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "152UkUPVGxc0"
   },
   "source": [
    "Let's multiply both sides with -1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAvwcd15HGBd"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=11Xst6go_BIf59i0K5083dT_JCVVCpkVZ' width=700></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QahUAUgoJhu7"
   },
   "source": [
    "If we were to ignore 2 in the equation, we can say that\n",
    "\n",
    "- **Residual** is **proportional** to the **negative of the graident of the Loss function w.r.t to model prediction**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z88-9U_mHFJr"
   },
   "source": [
    "We also know that,\n",
    "\n",
    "$$ŷ = F_k(x^i)$$\n",
    "\n",
    "\n",
    "Let's replace ŷ in the eq. with $F_k(x^i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uur0yhrtHFh1"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1Pjh4PLjI5XZigeMVFahQvoMbwJfGZwcl' width=700></center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTnC_Ap2Li4A"
   },
   "source": [
    "These negative graidents are called a **pseudo residuals**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCqdxDbZKniw"
   },
   "source": [
    "If it were a classification problem\n",
    "- we simply need to replace squared loss with log loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ri1KeBAbLRnj"
   },
   "source": [
    "#### But, how do we use these pseudo residuals ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esamaPHpLoML"
   },
   "source": [
    "Let's say we are building the model  and\n",
    "- we are at step j\n",
    "\n",
    "Let's term the model as **$M_j$**\n",
    "\n",
    "\n",
    "#### What do we need to train this model ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mvzn1eSdLtzS"
   },
   "source": [
    "We need {$x^i, err^i$}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ou1fKiuNMSqU"
   },
   "source": [
    "```\n",
    "Quiz 9 - Check your understanding\n",
    "\n",
    "\n",
    "Fill in the blanks:\n",
    "\n",
    "In order to build model M_j (i.e. model at step j). We need err_i i.e. error of previous models.\n",
    "\n",
    "err_i = y_i - ____ ?\n",
    "\n",
    "a. h_{j-1}(x)\n",
    "b. h_j(x)\n",
    "c. F_j(x)\n",
    "d. F_{j-1}(x)\n",
    "\n",
    "\n",
    "\n",
    "Correct option: d. F_{j-1}(x)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkMIx9KRNLRq"
   },
   "source": [
    "In order to calculate the error for Model $M_j$,\n",
    "- we calculate $err^i$ using $y^i - F_{j-1}(x^i)$\n",
    "\n",
    "\n",
    "The calculation is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQk_KoCuNa8W"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1Nh7ebdoPGTWCFzrxW80ivBPk3IJfvB9e' width=700></center>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiW6iuxvORvp"
   },
   "source": [
    "\n",
    "Instead of calculating the residual at each step,\n",
    "- we can simply calculate pseudo residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9A5cEE95O4Zf"
   },
   "source": [
    "\n",
    "\n",
    "<center><img src='https://drive.google.com/uc?id=1U1xE7Okq5jL_TED1z-7QhapDZooCyyEg' width=800></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErUq_UqJO7A_"
   },
   "source": [
    "#### How does using pseudo residual helping us ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_vaclKrO97C"
   },
   "source": [
    "As we have proved already using sqaured loss,\n",
    "- taking negative graident of loss is proportional to residual\n",
    "\n",
    "\n",
    "And By building model at each step,\n",
    "- we are **trying to minimize the residuals**\n",
    "\n",
    "\n",
    "So,\n",
    "- If we were to **use pseudo residual instead of residual**\n",
    "    - we are **indirectly minimizing the loss function** we have taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPon1Di1PmZm"
   },
   "source": [
    "Using this,\n",
    "- we can **minimize any custom loss function**\n",
    "- as long as it is **differentiable**.\n",
    "\n",
    "\n",
    "This is the **true power of gradient boosting**\n",
    "- which isn't given by another algo including Random forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIi-5M56eoqP"
   },
   "source": [
    "#### (Optional) Extra Read - Pseudo residual Log loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMTRcvOke2rg"
   },
   "source": [
    "The computation of Log loss pseudo residual is a bit math heavy.\n",
    "- hence, has been provided as extra read\n",
    "\n",
    "Do check it out: https://colab.research.google.com/drive/1TAp1vuROQyVyhntq8Bv4VhfshouSKvnB?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9SqCVtEB4dm"
   },
   "source": [
    "## Sklearn implemntation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udZ2F2sJ_s8j"
   },
   "source": [
    "Let's implement it on the one of the previously used dataset\n",
    "- Employee attrition dataset (used in DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YK15a4m5aZmd",
    "outputId": "3c725e99-f81b-445c-db14-a8d88e49a149"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=19L3rYatfhbBL1r5MHrv-p_oM2wlvrhqk\n",
      "To: E:\\Scaler-Notes-Git\\DSML-Notes\\M-15 ML-Supervised Algorithms\\06 ML Boosting -1\\preprocessed_X_sm.pickle\n",
      "\n",
      "  0%|          | 0.00/534k [00:00<?, ?B/s]\n",
      "100%|##########| 534k/534k [00:00<00:00, 6.44MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1OHLKJwA3qZopKPvlKoRldM6BvA1A4dYF\n",
      "To: E:\\Scaler-Notes-Git\\DSML-Notes\\M-15 ML-Supervised Algorithms\\06 ML Boosting -1\\X_test.pickle\n",
      "\n",
      "  0%|          | 0.00/111k [00:00<?, ?B/s]\n",
      "100%|##########| 111k/111k [00:00<00:00, 1.35MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1N7O_fWCTJLu8SIa_paKcDEzllgpMk8sK\n",
      "To: E:\\Scaler-Notes-Git\\DSML-Notes\\M-15 ML-Supervised Algorithms\\06 ML Boosting -1\\y_sm.pickle\n",
      "\n",
      "  0%|          | 0.00/15.4k [00:00<?, ?B/s]\n",
      "100%|##########| 15.4k/15.4k [00:00<00:00, 16.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=12Bh2AN8LcZAlg20ehpQrEWccUDaSdsOG\n",
      "To: E:\\Scaler-Notes-Git\\DSML-Notes\\M-15 ML-Supervised Algorithms\\06 ML Boosting -1\\y_test.pickle\n",
      "\n",
      "  0%|          | 0.00/9.49k [00:00<?, ?B/s]\n",
      "100%|##########| 9.49k/9.49k [00:00<00:00, 9.06MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 19L3rYatfhbBL1r5MHrv-p_oM2wlvrhqk\n",
    "!gdown 1OHLKJwA3qZopKPvlKoRldM6BvA1A4dYF\n",
    "!gdown 1N7O_fWCTJLu8SIa_paKcDEzllgpMk8sK\n",
    "!gdown 12Bh2AN8LcZAlg20ehpQrEWccUDaSdsOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lLOv-ppuaas8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Load data (deserialize)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed_X_sm.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m----> 4\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_pickle(handle)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m      7\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(handle)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load data (deserialize)\n",
    "with open('preprocessed_X_sm.pickle', 'rb') as handle:\n",
    "    X_train = pd.read_pickle(handle)\n",
    "\n",
    "with open('X_test.pickle', 'rb') as handle:\n",
    "    X_test = pd.read_pickle(handle)\n",
    "\n",
    "with open('y_sm.pickle', 'rb') as handle:\n",
    "    y_train = pd.read_pickle(handle)\n",
    "\n",
    "with open('y_test.pickle', 'rb') as handle:\n",
    "    y_test = pd.read_pickle(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s77U_wsT_owX"
   },
   "source": [
    "<br>\n",
    "\n",
    "But before that\n",
    "- we need to know what are the hyperparams we need to tune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WodjvUR2_sou"
   },
   "source": [
    "```\n",
    "Quiz 10 - Try it out\n",
    "\n",
    "What do you think are the hyperparameter for boosting ?\n",
    "\n",
    "\n",
    "a. Number of trees\n",
    "b. Depth\n",
    "c. which loss to use\n",
    "d. All of the above\n",
    "\n",
    "\n",
    "Correct option: d. All of the above\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYtN44zOBZnm"
   },
   "source": [
    "As we learnt that\n",
    "- there are M step in making the model\n",
    "- we need to control how many steps/iteration we want i.e. how many base learners we want\n",
    "\n",
    "As learners should be high bias low variance\n",
    "- we would have to experiment with depth of the tree\n",
    "- hence, it is again a hyperparam\n",
    "\n",
    "\n",
    "Boosting also gives us flexibility to choose the loss function\n",
    "- Hence, it is also an hyperparam.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Other than that,\n",
    "- there are hyperparam related to DT which we have already seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rN4iERcqByv2"
   },
   "source": [
    "Now, let's import the class from sklearn\n",
    "\n",
    "sklearn GBDT: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVQrni4LYjek"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQGz7aDOYjbs"
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=150, max_depth=2, loss = 'log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "ZOtGMddYYjY8",
    "outputId": "e91c01ea-91d9-4778-9768-3f1b48ed1722"
   },
   "outputs": [],
   "source": [
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NUd-PfoYYjWh",
    "outputId": "32d47c6e-02d2-4368-cd12-7c370cab8ac4"
   },
   "outputs": [],
   "source": [
    "gbc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUDBHomkZpQA",
    "outputId": "68000f97-6ca2-4d64-86ac-02f81fc66beb"
   },
   "outputs": [],
   "source": [
    "gbc.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtois1VaCRiS"
   },
   "source": [
    "Model is slightly overfitting.\n",
    "\n",
    "\n",
    "Do Note that:\n",
    "- It is very easy to overfit the boosting model\n",
    "- So, we have to careful while tuning it.\n",
    "\n",
    "We'll see in next lecture how to regularize GBDT\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
